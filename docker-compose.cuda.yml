# CUDA-enabled docker-compose for GPU acceleration
# Usage: docker compose -f docker-compose.cuda.yml up --build

services:
  api-service:
    build:
      context: .
      dockerfile: api/Dockerfile.cuda
    container_name: beach-monitor-api-cuda
    ports:
      - "8000:8000"
    environment:
      # AWS Credentials
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      
      # S3 Model Locations
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_MODEL_KEY=${S3_MODEL_KEY}
      
      # Force CUDA device
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./data:/app/data
      - ./models_cache:/app/models_cache
      - ./raw_seg_images:/app/raw_seg_images
    restart: unless-stopped
    # GPU support via NVIDIA Container Toolkit
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  agent-service:
    build:
      context: .
      dockerfile: agent/Dockerfile
    container_name: beach-monitor-agent
    ports:
      - "8501:8501"
    environment:
      # API Connection
      - API_BASE_URL=http://api-service:8000
      
      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - api-service
    restart: unless-stopped

networks:
  default:
    name: beach-monitor-network
